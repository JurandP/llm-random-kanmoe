# grid args
runner: "research.conditional.train.cc_train"
time: "5-05:00:00"
n_gpus: 1
cuda_visible: "7"

# train params
params:
  # model
  model_type: "bert"
  dataset_type: "wikibook"
  dmodel: 768
  n_att_heads: 12
  n_blocks: 12
  cutoff: 256
  batch_size: 64
  loss_checkpoint_chungs: 4

  n_steps: 150000
  grad_clip: 0.5
  lr_decay: 0.8
  lr_warmup_steps: 0
  lr_decay_interval: 10000

  logging_interval_heavy: 5000
  logging_interval_loss: 1000
  save_weights_path: "weights.ckpt"
  save_weights_interval: 1000

  use_neptune: true
  project_name: "pmtest/llm-random"
  name: "bert_massive"
  mixed_precision: true
  tags:
    - "bert"
    - "base"
    - "granular"
    - "512_experts"

  ff_mode: "expert_choice"
  n_experts: 512
  total_experts_width: 98304
  effective_dff: 3072


