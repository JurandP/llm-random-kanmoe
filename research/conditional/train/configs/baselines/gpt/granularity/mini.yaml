parent: research/conditional/train/configs/baselines/gpt/mini.yaml
md5_parent_hash: 019212718f2ace8645ddca8f28f6eaee

params:
  # technical/common params
  mixed_precision: true
  ff_mode: expert_choice
  softmax_over: experts
  group_granular_moe_by_batch: true
  use_full_einsum: true
  granular_moe_one_hot_impl: true
  ^flash_attention: [true]
  logging_interval_heavy: 1_000_000
  decoding_interval: 0
  gradient_checkpointing: true

  # init
  init_type: truncated_normal
  init_scale: 0.1

  # params of expert choice
  # total_experts_width: 32768
  # effective_dff: 1024
  # ^n_experts: [32]

  # ------ FILL IN BELOW ------
  n_steps: 1000
  scheduler: cosine
  learning_rate: 1e-4
  lr_warmup_steps: 10
  final_lr_step: 1000
  batch_size: 10
  cutoff: 256

  expert_size: 256
  n_experts: 4
  topk_fraction: 0.5

  dataset_type: wikibook
  use_dummy_dataset: true
