{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "SparseFF_PyTorch2.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "IYAsziKffBFV"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from opt_einsum import contract\n",
    "import opt_einsum"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "t = torch.tensor([[[1, 2], [2, 3]], [[4, 5], [6, 7]]])\n",
    "index = torch.tensor([0, 1])\n",
    "print(t[[0, 1], index, :])\n",
    "# torch.gather(t, 1, index)\n",
    "# torch.scatter(t, 1, index, t)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kLFo8DqOca_",
    "outputId": "4c3e6a2b-95dc-4cf0-ad0e-6bfd56e4ad59"
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [6, 7]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext line_profiler"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oe8egooBmpnN",
    "outputId": "abb4e6d4-ec26-4464-babe-45dc188161fb"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zpJj27OUdDtH"
   },
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "def assert_shape(x, shape):\n",
    "  if x.shape != shape:\n",
    "    raise AssertionError('invalid shape; got {} but expected {}.'.format(x.shape, shape))\n",
    "\n",
    "class DenseFF(nn.Module):\n",
    "  def __init__(self, d_model, d_ff):\n",
    "    super(DenseFF, self).__init__()\n",
    "    self.f1 = nn.Linear(d_model, d_ff)\n",
    "    self.f2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "  def forward(self, x):\n",
    "    ff = self.f1(x)\n",
    "    ff = F.relu(ff)\n",
    "    out = self.f2(ff)\n",
    "    return out\n",
    "\n",
    "class DenseFFEinsum(nn.Module):\n",
    "  def __init__(self, d_model, d_ff):\n",
    "    super(DenseFFEinsum, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_ff = d_ff\n",
    "\n",
    "    self.f1 = nn.Parameter(torch.Tensor(d_ff, d_model))\n",
    "    self.f2 = nn.Parameter(torch.Tensor(d_ff, d_model))\n",
    "\n",
    "  def forward(self, x):\n",
    "    inner = torch.einsum('bm,nm->bn', x, self.f1)\n",
    "    inner = F.relu(inner)\n",
    "    output = torch.einsum('bn,nm->bm', inner, self.f2)\n",
    "    assert_shape(output, (BATCH_SIZE, self.d_model))\n",
    "    return output\n",
    "\n",
    "CONTRACTS = dict()\n",
    "\n",
    "class LowRank(nn.Module):\n",
    "  def __init__(self, d_model, d_lowrank, d_output=None):\n",
    "    super(LowRank, self).__init__()\n",
    "    if d_output is None:\n",
    "      d_output = d_model\n",
    "    \n",
    "    self.f1 = nn.Parameter(torch.Tensor(d_model, d_lowrank))\n",
    "    self.f2 = nn.Parameter(torch.Tensor(d_lowrank, d_output))\n",
    "    # self.contract =\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = torch.einsum('bm,ml,lo->bo', x, self.f1, self.f2)\n",
    "    # out = contract('bm,ml,lo->bo', x, self.f1, self.f2)\n",
    "    # lowrank = torch.einsum('bm,ml->bl', x, self.f1)\n",
    "    # out = torch.einsum('bl,lo->bo', lowrank, self.f2)\n",
    "    return out\n",
    "\n",
    "\n",
    "def stop_gradient(x):\n",
    "  return x.detach()\n",
    "\n",
    "\n",
    "class GradientsLike(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(GradientsLike, self).__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x - stop_gradient(x)\n",
    "\n",
    "\n",
    "class SparseController(nn.Module):\n",
    "  def __init__(self, d_model, d_lowrank, d_ff, N):\n",
    "    super(SparseController, self).__init__()\n",
    "    assert d_ff % N == 0\n",
    "    self.lowrank = LowRank(d_model, d_lowrank, d_ff)\n",
    "    self.N = N\n",
    "    self.d_model = d_model\n",
    "    self.d_ff = d_ff\n",
    "    self.d_lowrank = d_lowrank\n",
    "\n",
    "  def forward(self, x):\n",
    "    N = self.N\n",
    "    assert_shape(x, (BATCH_SIZE, self.d_model))\n",
    "    out = self.lowrank(x)\n",
    "\n",
    "    out = out.view(BATCH_SIZE, -1, N)\n",
    "    assert out.shape == (BATCH_SIZE, self.d_ff//N, N)\n",
    "\n",
    "    # probs = F.softmax(out, dim=-1)\n",
    "    # TODO(jaszczur): change to discrete\n",
    "    # result = probs\n",
    "\n",
    "    result = out\n",
    "    assert result.shape == (BATCH_SIZE, self.d_ff//N, N)\n",
    "    return result\n",
    "\n",
    "class SparseFF(nn.Module):\n",
    "  def __init__(self, d_model, d_ff, d_lowrank, N):\n",
    "    super(SparseFF, self).__init__()\n",
    "    assert d_ff % N == 0\n",
    "\n",
    "    n_expertsets = d_ff // N\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_ff = d_ff\n",
    "    self.d_lowrank = d_lowrank\n",
    "    self.N = N\n",
    "    self.controller = SparseController(d_model, d_lowrank, d_ff, N)\n",
    "\n",
    "    self.f1 = nn.Parameter(torch.Tensor(n_expertsets, N, d_model))\n",
    "    # TODO(jaszczur): add biases\n",
    "    # self.f1 = nn.Linear(d_model, d_ff)\n",
    "    # self.f2 = nn.Linear(d_ff, d_model)\n",
    "    self.f2 = nn.Parameter(torch.Tensor(n_expertsets, N, d_model))\n",
    "\n",
    "  def forward(self, x):\n",
    "    N = self.N\n",
    "    assert x.shape == (BATCH_SIZE, self.d_model)\n",
    "    controller_output = self.controller(x)\n",
    "    if self.training:\n",
    "      inner = torch.einsum('bm,enm->ben', x, self.f1)\n",
    "      # inner = self.f1(x)\n",
    "      # inner = inner.view(BATCH_SIZE, self.d_ff//N, N)\n",
    "\n",
    "      assert_shape(inner, (BATCH_SIZE, self.d_ff//N, N))\n",
    "      assert_shape(controller_output, (BATCH_SIZE, self.d_ff//N, N))\n",
    "      inner = F.relu(inner) * controller_output\n",
    "\n",
    "      output = torch.einsum('ben,enm->bm', inner, self.f2)\n",
    "      # inner = inner.view(BATCH_SIZE, self.d_ff)\n",
    "      # output = self.f2(inner)\n",
    "      assert_shape(output, (BATCH_SIZE, self.d_model))\n",
    "      return output\n",
    "    else:\n",
    "      controller_indexes = torch.argmax(controller_output, dim=-1, keepdim=True)\n",
    "      \n",
    "      assert BATCH_SIZE == 1\n",
    "      assert_shape(controller_indexes, (BATCH_SIZE, self.d_ff//N, 1))\n",
    "      controller_indexes = controller_indexes.view(self.d_ff//N)\n",
    "      assert_shape(self.f1, (self.d_ff//N, N, self.d_model))\n",
    "\n",
    "      rangeE = torch.arange(self.d_ff//N)\n",
    "\n",
    "      f1p = self.f1[rangeE, controller_indexes]\n",
    "      f2p = self.f2[rangeE, controller_indexes]\n",
    "      # f1p = torch.index_select(self.f1, -1, controller_indexes)\n",
    "      # f2p = torch.index_select(self.f2, -1, controller_indexes)\n",
    "\n",
    "      assert_shape(f1p, (self.d_ff//N, self.d_model))\n",
    "      assert_shape(f2p, (self.d_ff//N, self.d_model))\n",
    "\n",
    "      inner = torch.einsum('bm,em->be', x, f1p)\n",
    "\n",
    "      assert_shape(inner, (BATCH_SIZE, self.d_ff//N))\n",
    "\n",
    "      inner = F.relu(inner)\n",
    "      output = torch.einsum('be,em->bm', inner, f2p)\n",
    "      assert_shape(output, (BATCH_SIZE, self.d_model))\n",
    "      return output\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "  def __init__(self, layer):\n",
    "    super(Residual, self).__init__()\n",
    "    self.fflayer = layer\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.fflayer(x) + x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "  def __init__(self, layers, d_model, d_ff, d_lowrank, sparsity, version):\n",
    "    super(Model, self).__init__()\n",
    "    if 'sparse' in version:\n",
    "      layer_fun = lambda: SparseFF(d_model, d_ff, d_lowrank, sparsity)\n",
    "    elif 'einsum' in version:\n",
    "      layer_fun = lambda: DenseFFEinsum(d_model, d_ff)\n",
    "    else:\n",
    "      layer_fun = lambda: DenseFF(d_model, d_ff)\n",
    "    self.layers = nn.ModuleList(\n",
    "        [Residual(layer_fun())\n",
    "         for i in range(layers)])\n",
    "    \n",
    "  def forward(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    return x"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model = Model(3, 128, 4*128, 32, 16, 'sparse')\n",
    "\n",
    "CUDA = torch.device(\"cuda\")\n",
    "\n",
    "def timemodel(batch, sample, layers, d_model, d_ff, d_lowrank, sparsity, version):\n",
    "  model = Model(layers, d_model, d_ff, d_lowrank, sparsity, version)\n",
    "  # model.to(CUDA)\n",
    "  sample = [torch.Tensor(np.random.random((batch, d_model)))]\n",
    "  if 'train' in version:\n",
    "    model.train()\n",
    "  else:\n",
    "    model.eval()\n",
    "  start = time.time()\n",
    "  with torch.no_grad():\n",
    "    for i in range(REPEAT):\n",
    "      for s in sample:\n",
    "        r = model(s)\n",
    "  return time.time() - start"
   ],
   "metadata": {
    "id": "9vEfY7nP4J0f"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 1\n",
    "SAMPLE = 100\n",
    "REPEAT = 100\n",
    "LAYERS = 20\n",
    "DMODEL = 1024\n",
    "DFF = 4 * 1024\n",
    "DLOWRANK = 32\n",
    "SPARSITY = 1024"
   ],
   "metadata": {
    "id": "y09tACJJORj5"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2087911424, 4294705152)\n",
      "(2773680128, 4294705152)\n",
      "(2773680128, 4294705152)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.mem_get_info())\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.mem_get_info())\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.mem_get_info())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%lprun -f SparseFF.forward print(\"sparse-eval\", timemodel(BATCH_SIZE, SAMPLE, LAYERS, DMODEL, DFF, DLOWRANK, SPARSITY, \"sparse-eval\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgrKAKNGktNL",
    "outputId": "70c2a9ab-97f0-4636-df8c-7cb3a6891761"
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse-eval 0.6223287582397461\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%lprun -f LowRank.forward print(\"sparse-eval\", timemodel(BATCH_SIZE, SAMPLE, LAYERS, DMODEL, DFF, DLOWRANK, SPARSITY, \"sparse-eval\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOTUNm54ku-9",
    "outputId": "0f86ad50-3ce0-4fb6-d5dd-1412af6b5f83"
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse-eval 0.7631902694702148\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%lprun -f SparseFF.forward print(\"sparse-train\", timemodel(BATCH_SIZE, SAMPLE, LAYERS, DMODEL, DFF, DLOWRANK, SPARSITY, \"sparse-train\"))"
   ],
   "metadata": {
    "id": "ZAeVq7ZSkroK"
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse-train 0.6327347755432129\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%lprun -f DenseFFEinsum.forward  print(\"dense-einsum\", timemodel(BATCH_SIZE, SAMPLE, LAYERS, DMODEL, DFF, DLOWRANK, SPARSITY, \"dense-einsum\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ysfcltkjkf-n",
    "outputId": "f6cea007-1e14-4331-b21d-c29c383ed4f0"
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense-einsum 3.8361973762512207\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 1\n",
    "timemodel(1, 1000, 16, 1024, 4*1024, 32, 64, True, eval=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wiOg_ywBLF4d",
    "outputId": "9670c3fc-004c-4ccf-d9fa-d3588986085d"
   },
   "execution_count": 13,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "timemodel() got an unexpected keyword argument 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m BATCH_SIZE \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtimemodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43meval\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: timemodel() got an unexpected keyword argument 'eval'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "timemodel(1, 1000, 16, 1024, 4*1024, 32, 64, False)"
   ],
   "metadata": {
    "id": "SSA_gEiX7RXe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b8ba75cc-52a7-445f-88d3-fbcb844bc9a8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b5x8dXCaeONE"
   },
   "source": [
    "# class ResNet(nn.Module):\n",
    "#   def __init__(self):\n",
    "#     super(ResNet, self).__init__()\n",
    "#     # After flattening an image of size 28x28 we have 784 inputs\n",
    "\n",
    "#     d_model = 128\n",
    "#     d_ff = 256\n",
    "#     num_layers = 3\n",
    "\n",
    "#     d_lowrank = 16\n",
    "#     N = 4\n",
    "\n",
    "#     if USE_SPARSE:\n",
    "#       fff = lambda: SparseFF(d_model, d_ff, d_lowrank, N)\n",
    "#     else:\n",
    "#       fff = lambda: DenseFF(d_model, d_ff)\n",
    "    \n",
    "\n",
    "#     self.fc1 = nn.Linear(784, d_model)\n",
    "#     self.layers = nn.ModuleList(\n",
    "#         [Residual(fff()) for i in range(num_layers)])\n",
    "#     self.output = nn.Linear(d_model, 10)\n",
    "\n",
    "#   def forward(self, x):\n",
    "#     assert x.shape == (BATCH_SIZE, 1, 28, 28)\n",
    "#     x = torch.flatten(x, 1)\n",
    "#     assert x.shape == (BATCH_SIZE, 28*28)\n",
    "#     x = self.fc1(x)\n",
    "#     for layer in self.layers:\n",
    "#       x = layer(x)\n",
    "#     x = self.output(x)\n",
    "#     output = F.log_softmax(x, dim=1)\n",
    "#     return output"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DMtap4QCfBH8"
   },
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         # After flattening an image of size 28x28 we have 784 inputs\n",
    "#         self.fc1 = nn.Linear(784, 128)\n",
    "#         self.fc2 = nn.Linear(128, 128)\n",
    "#         self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc3(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output\n",
    "\n",
    "\n",
    "# def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#       # print(data.shape)\n",
    "#       assert data.shape == (BATCH_SIZE, 1, 28, 28)  # B, 1(C/F), H, W\n",
    "#       data, target = data.to(device), target.to(device)\n",
    "#       optimizer.zero_grad()\n",
    "#       output = model(data)\n",
    "#       loss = F.nll_loss(output, target)\n",
    "#       loss.backward()\n",
    "#       optimizer.step()\n",
    "#       if batch_idx % log_interval == 0:\n",
    "#           print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "#               epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#               100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "# def test(model, device, test_loader):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             test_loss += F.nll_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "\n",
    "#     print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WgfUP23AfBMd"
   },
   "source": [
    "# BATCH_SIZE = 128\n",
    "# test_BATCH_SIZE = 1000\n",
    "# epochs = 2\n",
    "# lr = 1e-3\n",
    "# # use_cuda = False\n",
    "# seed = 1\n",
    "# log_interval = 10000\n",
    "\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# torch.manual_seed(seed)\n",
    "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# train_kwargs = {\"BATCH_SIZE\": BATCH_SIZE}\n",
    "# test_kwargs = {\"BATCH_SIZE\": test_BATCH_SIZE}\n",
    "# if use_cuda:\n",
    "#     cuda_kwargs = {\"num_workers\": 1,\n",
    "#                     \"pin_memory\": True,\n",
    "#                     \"shuffle\": True}\n",
    "#     train_kwargs.update(cuda_kwargs)\n",
    "#     test_kwargs.update(cuda_kwargs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o0KPoUtsfBOs"
   },
   "source": [
    "# transform=transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.1307,), (0.3081,))\n",
    "#     ])\n",
    "# dataset1 = datasets.MNIST(\"../data\", train=True, download=True,\n",
    "#                     transform=transform)\n",
    "# dataset2 = datasets.MNIST(\"../data\", train=False,\n",
    "#                     transform=transform)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "ezvIQbgsfBRT",
    "outputId": "7fa13fc7-4f5e-41df-b080-675bec9e5ffa"
   },
   "source": [
    "# USE_SPARSE = False\n",
    "\n",
    "# model = ResNet().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "#     test(model, device, test_loader)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DQMSSwuifBTo"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JX_2rCycfBWU"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}